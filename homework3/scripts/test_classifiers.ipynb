{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first define classifiers and some functions that we will need later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "# Disable warnings for some sklearn classifiers\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    \"knn, k = 1\": KNeighborsClassifier(1),\n",
    "    \"knn, k = 1, weights = distance\": KNeighborsClassifier(1, weights='distance'),\n",
    "    \"knn, k = 3\": KNeighborsClassifier(3),\n",
    "    \"knn, k = 3, weights = distance\": KNeighborsClassifier(3, weights='distance'),\n",
    "    \"knn, k = 5\": KNeighborsClassifier(5),\n",
    "    \"knn, k = 5, weights = distance\": KNeighborsClassifier(5, weights='distance'),\n",
    "    \"knn, k = 7\": KNeighborsClassifier(7),\n",
    "    \"knn, k = 7, weights = distance\": KNeighborsClassifier(7, weights='distance'),\n",
    "    \"decision tree, gini\": DecisionTreeClassifier(criterion='gini'),\n",
    "    \"decision tree, entropy\": DecisionTreeClassifier(criterion='entropy'),\n",
    "    \"random forest, gini\": RandomForestClassifier(n_estimators=100, criterion='gini'),\n",
    "    \"random forest, entropy\": RandomForestClassifier(n_estimators=100, criterion='entropy'),\n",
    "    \"naive bayes\": GaussianNB(),\n",
    "    \"support vector machine, kernel=linear, c=0.025\": SVC(kernel=\"linear\", C=0.025),\n",
    "    \"support vector machine, kernel=linear, c=0.05\": SVC(kernel=\"linear\", C=0.05),\n",
    "    \"support vector machine, kernel=linear, c=0.1\": SVC(kernel=\"linear\", C=0.1),\n",
    "    \"support vector machine, kernel=linear, c=0.2\": SVC(kernel=\"linear\", C=0.2),\n",
    "    \"support vector machine, kernel=rbf, c=0.025\": SVC(kernel='rbf', C=0.1)\n",
    "}\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a)*np.linalg.norm(b))\n",
    "\n",
    "def evaluate_classifiers(x_train, x_test, y_train, y_test, n_iterations=1):\n",
    "    for classifier_name in classifiers:\n",
    "        scores = []\n",
    "        for i in range(n_iterations):\n",
    "            classifier = classifiers[classifier_name]\n",
    "            classifier.fit(x_train, y_train)\n",
    "            test_score = classifier.score(x_test, y_test)\n",
    "            scores.append(test_score)\n",
    "        print(\"{}: {:.3f}\".format(classifier_name, np.average(scores)))\n",
    "\n",
    "def prepare_train_test_set(train_file, test_file=None, normalize=True, merge_datasets=False):\n",
    "    data_train = pd.read_csv(train_file)\n",
    "    \n",
    "    if test_file is None:\n",
    "        x_train = data_train.iloc[:, :-1].values\n",
    "        y_train = data_train.iloc[:, 128].values\n",
    "\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2)\n",
    "\n",
    "    else:\n",
    "        data_test = pd.read_csv(test_file)\n",
    "\n",
    "        if merge_datasets:\n",
    "            data_train = data_train.append(data_test)\n",
    "            \n",
    "            x_train = data_train.iloc[:, :-1].values\n",
    "            y_train = data_train.iloc[:, 128].values\n",
    "\n",
    "            from sklearn.model_selection import train_test_split\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2)\n",
    "        \n",
    "        else:\n",
    "            x_train = data_train.iloc[:, :-1].values\n",
    "            y_train = data_train.iloc[:, 128].values\n",
    "            x_test = data_test.iloc[:, :-1].values\n",
    "            y_test = data_test.iloc[:, 128].values\n",
    "\n",
    "    # Normalize the feautures\n",
    "    if normalize:\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(x_train)\n",
    "        x_train = scaler.transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating classifiers\n",
    "Let's first train and test our models on images taken in gazebo simulation.\n",
    "\n",
    "We can see that most of the classifiers perform extremely well. The only exception being decision tree, but it still works fairly well.\n",
    "\n",
    "There are a few reasons why all the classifiers work really well.\n",
    "\n",
    "1. The `face_recognition` library does a very good job encoding the faces into embeddings. As we can see in an example later in this notebook, when using only the original images of the faces as train set and faces from simulation as test set, the classifiers still perform very well.\n",
    "\n",
    "2. We only need to recognize 21 faces, which makes this problem much easier.\n",
    "\n",
    "3. The nature of the simulation makes this task easier as well. There is no blur in the images recorded in the simulation and the lighting conditions are very simple.\n",
    "\n",
    "We can notice that KNeighbors algorithm works very well, despite our high dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "knn, k = 7, weights = distance: 1.000\nsupport vector machine, kernel=linear, c=0.05: 1.000\ndecision tree, entropy: 0.850\nrandom forest, gini: 0.995\nrandom forest, entropy: 0.998\nsupport vector machine, kernel=rbf, c=0.025: 0.124\nknn, k = 1, weights = distance: 1.000\nnaive bayes: 0.990\ndecision tree, gini: 0.855\nsupport vector machine, kernel=linear, c=0.1: 1.000\nsupport vector machine, kernel=linear, c=0.2: 1.000\nknn, k = 3, weights = distance: 1.000\nsupport vector machine, kernel=linear, c=0.025: 1.000\nknn, k = 5, weights = distance: 1.000\nknn, k = 1: 1.000\nknn, k = 3: 0.995\nknn, k = 5: 0.995\nknn, k = 7: 0.995\n"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = prepare_train_test_set('../encodings/faces_all_simulation.txt')\n",
    "\n",
    "evaluate_classifiers(x_train, x_test, y_train, y_test, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that training the models on images from the simulation and the evaluating them on real images yields us very bad results.\n",
    "This is probably due to the fact that the conditions in which the images were taken are very different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'prepare_train_test_set' is not defined",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-561743503bf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_train_test_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../encodings/faces_all_simulation.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../encodings/faces_all_camera.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mevaluate_classifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prepare_train_test_set' is not defined"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = prepare_train_test_set('../encodings/faces_all_simulation.txt', '../encodings/faces_all_camera.txt')\n",
    "\n",
    "evaluate_classifiers(x_train, x_test, y_train, y_test, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that training the models on images taken on a physical camera gives us very good results as well. This means that our pipeline could be used for face recognition on real robots as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'prepare_train_test_set' is not defined",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-64ac42b010e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_train_test_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../encodings/faces_all_camera.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mevaluate_classifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prepare_train_test_set' is not defined"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = prepare_train_test_set('../encodings/faces_all_camera.txt')\n",
    "\n",
    "evaluate_classifiers(x_train, x_test, y_train, y_test, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixing the two datasets (images taken in ros and images taken with a physical camera) yields very good results as well. They are not as good as with training the models on the two datasets seperately. We see no value in this approach because real world and simulation are two very different environments and it would be better to create a two classifiers, one for each environment than one classifier for both occasions. We could however in this way teach the model to recognize faces in different lighting conditions, but this is easier done with manipulating images taken in the simulation, for example darkening them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'prepare_train_test_set' is not defined",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1f5440b32296>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_train_test_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../encodings/faces_all_simulation.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../encodings/faces_all_camera.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_datasets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mevaluate_classifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prepare_train_test_set' is not defined"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = prepare_train_test_set('../encodings/faces_all_simulation.txt', '../encodings/faces_all_camera.txt', merge_datasets=True)\n",
    "\n",
    "evaluate_classifiers(x_train, x_test, y_train, y_test, 20)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python271264bitvenvvenv0b5ba3da51994d01aea243c810de5cf8",
   "display_name": "Python 2.7.12 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}