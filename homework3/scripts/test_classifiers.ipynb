{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first define classifiers and some functions that we will need later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "# Disable warnings for some sklearn classifiers\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    \"knn, k = 1\": KNeighborsClassifier(1),\n",
    "    \"knn, k = 1, weights = distance\": KNeighborsClassifier(1, weights='distance'),\n",
    "    \"knn, k = 3\": KNeighborsClassifier(3),\n",
    "    \"knn, k = 3, weights = distance\": KNeighborsClassifier(3, weights='distance'),\n",
    "    \"knn, k = 5\": KNeighborsClassifier(5),\n",
    "    \"knn, k = 5, weights = distance\": KNeighborsClassifier(5, weights='distance'),\n",
    "    \"knn, k = 7\": KNeighborsClassifier(7),\n",
    "    \"knn, k = 7, weights = distance\": KNeighborsClassifier(7, weights='distance'),\n",
    "    \"decision tree, gini\": DecisionTreeClassifier(criterion='gini'),\n",
    "    \"decision tree, entropy\": DecisionTreeClassifier(criterion='entropy'),\n",
    "    \"random forest, gini\": RandomForestClassifier(n_estimators=100, criterion='gini'),\n",
    "    \"random forest, entropy\": RandomForestClassifier(n_estimators=100, criterion='entropy'),\n",
    "    \"naive bayes\": GaussianNB(),\n",
    "    \"support vector machine, kernel=linear, c=0.025\": SVC(kernel=\"linear\", C=0.025),\n",
    "    \"support vector machine, kernel=linear, c=0.05\": SVC(kernel=\"linear\", C=0.05),\n",
    "    \"support vector machine, kernel=linear, c=0.1\": SVC(kernel=\"linear\", C=0.1),\n",
    "    \"support vector machine, kernel=linear, c=0.2\": SVC(kernel=\"linear\", C=0.2),\n",
    "}\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a)*np.linalg.norm(b))\n",
    "\n",
    "def evaluate_classifiers(x_train, x_test, y_train, y_test):\n",
    "    for classifier_name in classifiers:\n",
    "        classifier = classifiers[classifier_name]\n",
    "        classifier.fit(x_train, y_train)\n",
    "        test_score = classifier.score(x_test, y_test)\n",
    "        print(\"{}: {}\".format(classifier_name, test_score))\n",
    "\n",
    "def prepare_train_test_set(train_file, test_file=None, normalize=True):\n",
    "    # Read the data from csv file\n",
    "    dataset_train = pd.read_csv(train_file)\n",
    "\n",
    "    # Split data into features and labels\n",
    "    x_train = dataset_train.iloc[:, :-1].values\n",
    "    y_train = dataset_train.iloc[:, 128].values\n",
    "    \n",
    "    if test_file is None:\n",
    "        # Split the dataset_train into train and test set\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2)\n",
    "    else:\n",
    "        # Or read the test data from csv file\n",
    "        dataset_test = pd.read_csv(test_file)\n",
    "        x_test = dataset_test.iloc[:, :-1].values\n",
    "        y_test = dataset_test.iloc[:, 128].values\n",
    "    \n",
    "\n",
    "    # Normalize features for better results\n",
    "    if normalize:\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(x_train)\n",
    "        x_train = scaler.transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating classifiers\n",
    "Let's first train and test our models on images taken in gazebo simulation.\n",
    "\n",
    "We can see that most of the classifiers perform extremely well. The only exception being decision tree, but it still works fairly well.\n",
    "\n",
    "There are a few reasons why all the classifiers work really well.\n",
    "\n",
    "1. The `face_recognition` library does a very good job encoding the faces into embeddings. As we can see in an example later in this notebook, when using only the original images of the faces as train set and faces from simulation as test set, the classifiers still perform very well.\n",
    "\n",
    "2. We only need to recognize 21 faces, which makes this problem much easier.\n",
    "\n",
    "3. The nature of the simulation makes this task easier as well. There is no blur in the images recorded in the simulation and the lighting conditions are very simple.\n",
    "\n",
    "We can notice that KNeighbors algorithm works very well, despite feeding it high dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "knn, k = 7, weights = distance: 0.99481865285\nsupport vector machine, kernel=linear, c=0.05: 0.989637305699\ndecision tree, entropy: 0.79274611399\nrandom forest, gini: 0.984455958549\nrandom forest, entropy: 0.989637305699\nknn, k = 1, weights = distance: 0.99481865285\nnaive bayes: 0.989637305699\ndecision tree, gini: 0.849740932642\nsupport vector machine, kernel=linear, c=0.1: 0.989637305699\nsupport vector machine, kernel=linear, c=0.2: 0.989637305699\nknn, k = 3, weights = distance: 0.99481865285\nsupport vector machine, kernel=linear, c=0.025: 0.989637305699\nknn, k = 5, weights = distance: 0.99481865285\nknn, k = 1: 0.99481865285\nknn, k = 3: 0.99481865285\nknn, k = 5: 0.984455958549\nknn, k = 7: 0.984455958549\n"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = prepare_train_test_set('../encodings/faces_all_simulation.txt')\n",
    "\n",
    "evaluate_classifiers(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python271264bitvenvvenv0b5ba3da51994d01aea243c810de5cf8",
   "display_name": "Python 2.7.12 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}